{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import Libraries\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.autograd import Variable\n",
            "from torch.utils.data import DataLoader, TensorDataset, Dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cuda\n"
               ]
            }
         ],
         "source": [
            "# Use GPU if available, else use CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "class RNN(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(RNN, self).__init__()\n",
            "        self.layers = torch.nn.Sequential(torch.nn.Linear(108, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 128),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(128, 73))\n",
            "        \n",
            "    def forward(self, inputs, hidden):\n",
            "        # combined = torch.tensor([inputs, hidden]).to(inputs.device)\n",
            "        # print(inputs.shape)\n",
            "        # print(hidden.shape)\n",
            "        combined = torch.cat([inputs, hidden]).to(inputs.device)\n",
            "        out = self.layers(combined)\n",
            "        return out"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model = RNN().to(device)\n",
            "model.load_state_dict(torch.load('weights/rnn_4layer_256_37.pth'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "def predict(input, model, device):\n",
            "    move_mapping = [\"#\", \"U\", \"U'\", \"U2\", \"D\", \"D'\", \"D2\", \"L\", \"L'\", \"L2\", \"R\", \n",
            "                     \"R'\", \"R2\", \"F\", \"F'\", \"F2\", \"B\", \"B'\", \"B2\"]\n",
            "    input_string = ''.join(input)\n",
            "    input_int_list = [int(i) for i in input_string]\n",
            "    input_tensor = torch.tensor(input_int_list)\n",
            "    with torch.no_grad():\n",
            "        hidden= torch.zeros(54).to(device)\n",
            "        output = model(input_tensor.to(device), hidden)\n",
            "        out, hidden = output[0:19], output[19::]\n",
            "        pred_move = torch.argmax(out)\n",
            "        prediction = move_mapping[pred_move]\n",
            "    return prediction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Example of running input:\n",
            "Each cube face inputed as a string."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "\"R'\""
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "predict([\"302202434\", \"400513312\", \"051124551\", \"345533221\", \"005140045\", \"322153441\"], model, device=device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'#'"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "predict([\"000000000\", \"111111111\", \"222222222\", \"333333333\", \"444444444\", \"555555555\"], model, device=device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# def predict(input, model, device):\n",
            "#     move_mapping = [\"#\", \"U\", \"U'\", \"U2\", \"D\", \"D'\", \"D2\", \"L\", \"L'\", \"L2\", \"R\", \n",
            "#                      \"R'\", \"R2\", \"F\", \"F'\", \"F2\", \"B\", \"B'\", \"B2\"]\n",
            "#     with torch.no_grad():\n",
            "#         hidden= torch.zeros(54).to(device)\n",
            "#         output = model(input.to(device), hidden)\n",
            "#         out, hidden = output[0:19], output[19::]\n",
            "#         pred_move = torch.argmax(out)\n",
            "#         prediction = move_mapping[pred_move]\n",
            "#     return prediction"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# input = [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5]\n",
            "# # print(predict(input ,model, device=device))"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
