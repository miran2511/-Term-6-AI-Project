{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import Libraries\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.autograd import Variable\n",
            "from sklearn.model_selection import train_test_split\n",
            "from torch.utils.data import DataLoader, TensorDataset, Dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cuda\n"
               ]
            }
         ],
         "source": [
            "# Use GPU if available, else use CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_7596\\1228740871.py:1: DtypeWarning: Columns (68,69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training0_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "# df = pd.read_csv('dataset/training0_sort.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df.info()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# display datatypes\n",
            "# df.dtypes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df.dtypes.value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# run this\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\512921396.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training5_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "# df = pd.read_csv('dataset/training5_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# df.iloc[1,1:].values\n",
            "# type(df.iloc[1,:].values)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Our custom Dataset object\n",
            "class RubiksDataset(Dataset):\n",
            "    def __init__(self, df):\n",
            "        self.df = df\n",
            "        move_dict = {\"#\":0, \"U\":1, \"U'\":2, \"U2\":3, \"D\":4, \"D'\":5, \"D2\":6, \"L\":7, \"L'\":8, \"L2\":9, \"R\":10, \n",
            "                     \"R'\":11, \"R2\":12, \"F\":13, \"F'\":14, \"F2\":15, \"B\":16, \"B'\":17, \"B2\":18}\n",
            "        # list of list, where inner list is an entire sequence.\n",
            "        self.states = [] #is now a list of list of list :D\n",
            "        self.moves = [] #list of list\n",
            "\n",
            "        for i in range(len(df)):\n",
            "            statelist = []\n",
            "            movelist = []\n",
            "            statemoves = df.iloc[i,1:]\n",
            "            for line in statemoves:\n",
            "                split = line.split(\",\")\n",
            "                # state_as_int = int(split[0].replace(\" \",\"\"))/(10**54)\n",
            "                state_as_str_list = split[0].split(\" \")\n",
            "                state_as_int_list = [int(i) for i in state_as_str_list]\n",
            "                # above sets the input states to int values instead of string\n",
            "                # below sets the string move into an int value,\n",
            "                move_as_int = move_dict.get(split[1])\n",
            "\n",
            "                statelist.append(state_as_int_list)\n",
            "                movelist.append(move_as_int)\n",
            "            self.states.append(statelist)\n",
            "            self.moves.append(movelist)\n",
            "\n",
            "\n",
            "        \n",
            "    def __len__(self):\n",
            "        return len(self.moves)\n",
            "        \n",
            "    def __getitem__(self, index):\n",
            "        # inputs = torch.tensor(self.inputs[index]).float()\n",
            "        # outputs = torch.tensor(self.outputs[index]).float()\n",
            "        # print(self.states[index])\n",
            "        inputs = torch.tensor(self.states[index]) # list of list, each index is a state vector\n",
            "        outputs = torch.tensor(self.moves[index]) # list, each index is the move set of that sequence(index)\n",
            "        return inputs, outputs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training5_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# seqcount = 0\n",
            "# for inputs, outputs in dataloader:\n",
            "#     seqcount +=1\n",
            "#     print(outputs)\n",
            "#     # for i in outputs:\n",
            "#     #     print(i)\n",
            "#     print(seqcount)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "class RNN(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(RNN, self).__init__()\n",
            "        self.layers = torch.nn.Sequential(torch.nn.Linear(108, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 128),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(128, 73))\n",
            "        \n",
            "    def forward(self, inputs, hidden):\n",
            "        # combined = torch.tensor([inputs, hidden]).to(inputs.device)\n",
            "        # print(inputs.shape)\n",
            "        # print(hidden.shape)\n",
            "        combined = torch.cat([inputs, hidden]).to(inputs.device)\n",
            "        out = self.layers(combined)\n",
            "        return out"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Sequential(\n",
                  "  (0): Linear(in_features=108, out_features=256, bias=True)\n",
                  "  (1): ReLU()\n",
                  "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
                  "  (3): ReLU()\n",
                  "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
                  "  (5): ReLU()\n",
                  "  (6): Linear(in_features=128, out_features=73, bias=True)\n",
                  ")\n"
               ]
            }
         ],
         "source": [
            "# model = RNN().to(device)\n",
            "# print(model.layers)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "def train(model, dataloader, num_epochs, learning_rate, device):\n",
            "    criterion = torch.nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
            "    # hidden = torch.tensor([0]).to(device)\n",
            "    # hidden= torch.zeros(1, 81, 54).to(device)\n",
            "    for epoch in range(num_epochs):\n",
            "        count = 0\n",
            "        loss = 0\n",
            "\n",
            "        \n",
            "        # optimizer.zero_grad()\n",
            "        for inputs, targets in dataloader:\n",
            "            # inputs = inputs.permute(1,0,2)\n",
            "            # need another loop inside.\n",
            "            correct = 0\n",
            "            pred = 0\n",
            "            \n",
            "            # reset hidden here\n",
            "            loss = 0\n",
            "            optimizer.zero_grad()\n",
            "            # \n",
            "            for i in range(len(inputs)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(inputs[i])):\n",
            "                    outputs = model(inputs[i][j].to(device), hidden)\n",
            "                    out, hidden = outputs[0:19], outputs[19::]\n",
            "                    # print(out.shape)\n",
            "                    # print(hidden.shape)\n",
            "                    # print(targets[i][j].shape)\n",
            "\n",
            "                    # print((torch.argmax(out) == targets[i][j]).item())\n",
            "                    correct += (torch.argmax(out) == targets[i][j]).item()\n",
            "                    pred += 1\n",
            "                    loss += criterion(out.to(device), targets[i][j].to(device)) / len(inputs[i]) / len(inputs)\n",
            "                # print(loss)\n",
            "            batch_accuracy = correct/pred\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "            count +=1\n",
            "            print(f\"Batch number: {count}\")\n",
            "            print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "        \n",
            "        # loss /= len(inputs)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        #     outputs = model(inputs.to(device), hidden)\n",
            "        #     out, hidden = outputs[0], outputs[1]\n",
            "        #     loss += criterion(out.to(device), targets.to(device))\n",
            "        # loss /= len(dataloader)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Last Batch Accuracy: {batch_accuracy*100:.2f}%\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\1102419214.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training6_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training6_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7324924698795181\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.6535203313253012\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7266566265060241\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.6977597891566265\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.6919239457831325\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7179969879518072\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7244917168674698\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7258094879518072\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7265625\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.721667921686747\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7195971385542169\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7230798192771084\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7358810240963856\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.724585843373494\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7275978915662651\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7248682228915663\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.728539156626506\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7239269578313253\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7288215361445783\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.725621234939759\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7287274096385542\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7344691265060241\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7371046686746988\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7360692771084337\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7352221385542169\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7355986445783133\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7341867469879518\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7335278614457831\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7296686746987951\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7321159638554217\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7388930722891566\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7354103915662651\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7381400602409639\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.733433734939759\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7311746987951807\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7361634036144579\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7318335843373494\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.735316265060241\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7406814759036144\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7306099397590361\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7339984939759037\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7357868975903614\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7337161144578314\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7342808734939759\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7358810240963856\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7403990963855421\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7371987951807228\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7317394578313253\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7319277108433735\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7288215361445783\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7377635542168675\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7312688253012049\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7369164156626506\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7341867469879518\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7333396084337349\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7390813253012049\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.736351656626506\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7422816265060241\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7398343373493976\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7410579819277109\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7301393072289156\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7379518072289156\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7437876506024096\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7421875\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7403990963855421\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.732398343373494\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7371987951807228\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7387048192771084\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.740210843373494\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7351280120481928\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7355045180722891\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7411521084337349\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7455760542168675\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7360692771084337\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7355045180722891\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7339043674698795\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7407756024096386\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7388930722891566\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7364457831325302\n",
                  "Epoch 1/2, Loss: 0.8047, Last Batch Accuracy: 73.64%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7395519578313253\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7350338855421686\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7366340361445783\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7407756024096386\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7382341867469879\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7479292168674698\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7373870481927711\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7454819277108434\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7416227409638554\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7396460843373494\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7362575301204819\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7332454819277109\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7424698795180723\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7370105421686747\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.736351656626506\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7458584337349398\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7384224397590361\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7438817771084337\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7417168674698795\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7381400602409639\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7369164156626506\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7405873493975904\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7400225903614458\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7347515060240963\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7375753012048193\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7444465361445783\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7419992469879518\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7452936746987951\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7443524096385542\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7419992469879518\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7449171686746988\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7408697289156626\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7387989457831325\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7356927710843374\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7383283132530121\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7427522590361446\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7433170180722891\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7376694277108434\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7489646084337349\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7461408132530121\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7426581325301205\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7397402108433735\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7421875\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7429405120481928\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.744164156626506\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7428463855421686\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7405873493975904\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7397402108433735\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.748023343373494\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7401167168674698\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7458584337349398\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7394578313253012\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7398343373493976\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7477409638554217\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7424698795180723\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7458584337349398\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7467996987951807\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7383283132530121\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.735316265060241\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7385165662650602\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7425640060240963\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7428463855421686\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7423757530120482\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7409638554216867\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7386106927710844\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7436935240963856\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7451995481927711\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7417168674698795\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7484939759036144\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.745105421686747\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7408697289156626\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7421875\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7366340361445783\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7498117469879518\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7395519578313253\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.744164156626506\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7421875\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7481174698795181\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7545180722891566\n",
                  "Epoch 2/2, Loss: 0.7688, Last Batch Accuracy: 75.45%\n"
               ]
            }
         ],
         "source": [
            "# Train the model\n",
            "# model = RNN().to(device)\n",
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_20.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\1325915394.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training7_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training7_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7384717987804879\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.6777820121951219\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7235137195121951\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7117949695121951\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.704077743902439\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7069359756097561\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7225609756097561\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7350419207317073\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7322789634146342\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.721608231707317\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7251333841463414\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7178925304878049\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7303734756097561\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7322789634146342\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7380907012195121\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7342797256097561\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7352324695121951\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7381859756097561\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7399009146341463\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7332317073170732\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7387576219512195\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7419969512195121\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7408536585365854\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7364710365853658\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7363757621951219\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7457126524390244\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7360899390243902\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7359946646341463\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7386623475609756\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7396150914634146\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7386623475609756\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7366615853658537\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7379954268292683\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7404725609756098\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7347560975609756\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.743235518292683\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7433307926829268\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7424733231707317\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7435213414634146\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7348513719512195\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7408536585365854\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7351371951219512\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7401867378048781\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7401867378048781\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7379954268292683\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7403772865853658\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.739329268292683\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7447599085365854\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7404725609756098\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7458079268292683\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7440929878048781\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7494283536585366\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7458079268292683\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7461890243902439\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7394245426829268\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7461890243902439\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7438071646341463\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7425685975609756\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7409489329268293\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7369474085365854\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7407583841463414\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7404725609756098\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7466653963414634\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7399009146341463\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.75\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7398056402439024\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7457126524390244\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7401867378048781\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7467606707317073\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7461890243902439\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7401867378048781\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7473323170731707\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7398056402439024\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7479039634146342\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7399009146341463\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.743140243902439\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7429496951219512\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7386623475609756\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.75\n",
                  "Epoch 1/2, Loss: 0.7100, Last Batch Accuracy: 75.00%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7426638719512195\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7480945121951219\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7439977134146342\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7408536585365854\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7439024390243902\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7345655487804879\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.74609375\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7360899390243902\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.737233231707317\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.745141006097561\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7511432926829268\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7403772865853658\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7459032012195121\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7479039634146342\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7454268292682927\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7364710365853658\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7408536585365854\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7437118902439024\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7415205792682927\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.743140243902439\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7523818597560976\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7457126524390244\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7430449695121951\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7417111280487805\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7512385670731707\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.741234756097561\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7478086890243902\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7488567073170732\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7442835365853658\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7452362804878049\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7550495426829268\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7446646341463414\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7500952743902439\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7482850609756098\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7472370426829268\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7454268292682927\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.749047256097561\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7481897865853658\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7455221036585366\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7439977134146342\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7475228658536586\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7466653963414634\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7474275914634146\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7472370426829268\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7508574695121951\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7455221036585366\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7513338414634146\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7433307926829268\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7459032012195121\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7494283536585366\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7469512195121951\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7449504573170732\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.751048018292683\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7488567073170732\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.745141006097561\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7505716463414634\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7452362804878049\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7429496951219512\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7454268292682927\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7387576219512195\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7464748475609756\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7484756097560976\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7447599085365854\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7442835365853658\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7468559451219512\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.749047256097561\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7515243902439024\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.743235518292683\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7390434451219512\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7526676829268293\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7413300304878049\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.739233993902439\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7488567073170732\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.748951981707317\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7402820121951219\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7468559451219512\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7477134146341463\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7479992378048781\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7583841463414634\n",
                  "Epoch 2/2, Loss: 0.7194, Last Batch Accuracy: 75.84%\n"
               ]
            }
         ],
         "source": [
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_22.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\1852383510.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training8_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training8_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7470100308641975\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.6572145061728395\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7188464506172839\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7087191358024691\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7047646604938271\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7215470679012346\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7060185185185185\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7139274691358025\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7198109567901234\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7350501543209876\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7311921296296297\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7318672839506173\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7355324074074074\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.730516975308642\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7308063271604939\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.738329475308642\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7337962962962963\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7337962962962963\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7331211419753086\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7318672839506173\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7406442901234568\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7375578703703703\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7419945987654321\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7391975308641975\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7359182098765432\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7353395061728395\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7435378086419753\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7373649691358025\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7396797839506173\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7413194444444444\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7420910493827161\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7385223765432098\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7389081790123457\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7444058641975309\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7395833333333334\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7438271604938271\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7511574074074074\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7430555555555556\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7419945987654321\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7416087962962963\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7425733024691358\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7523148148148148\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7408371913580247\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7456597222222222\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7463348765432098\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7426697530864198\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7438271604938271\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7493248456790124\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7492283950617284\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7488425925925926\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7457561728395061\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7491319444444444\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7428626543209876\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7430555555555556\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7471064814814815\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.744116512345679\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7432484567901234\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7462384259259259\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7445023148148148\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7462384259259259\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7465277777777778\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7472029320987654\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7505787037037037\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7437307098765432\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7447916666666666\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7502893518518519\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7445023148148148\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7482638888888888\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7494212962962963\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7403549382716049\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7467206790123457\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7410300925925926\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7445023148148148\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7506751543209876\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7470100308641975\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7426697530864198\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7410300925925926\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7427662037037037\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7646604938271605\n",
                  "Epoch 1/2, Loss: 0.7195, Last Batch Accuracy: 76.47%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7456597222222222\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7440200617283951\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7448881172839507\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7543402777777778\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7517361111111112\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7487461419753086\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7507716049382716\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7483603395061729\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7482638888888888\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7512538580246914\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7515432098765432\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7472029320987654\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7421875\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7534722222222222\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7434413580246914\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7512538580246914\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7414158950617284\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7511574074074074\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7497106481481481\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7490354938271605\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7468171296296297\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7510609567901234\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7484567901234568\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7450810185185185\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7464313271604939\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7373649691358025\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7529899691358025\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7469135802469136\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7470100308641975\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7532793209876543\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7413194444444444\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7489390432098766\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7481674382716049\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7455632716049383\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7419945987654321\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7491319444444444\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7445023148148148\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7472993827160493\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7458526234567902\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7459490740740741\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7566550925925926\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7566550925925926\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7401620370370371\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.746141975308642\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7516396604938271\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7513503086419753\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7479745370370371\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7475887345679012\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7505787037037037\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7532793209876543\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7567515432098766\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7490354938271605\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7547260802469136\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7601273148148148\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7447916666666666\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7504822530864198\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7488425925925926\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7530864197530864\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7542438271604939\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7467206790123457\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7508680555555556\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7469135802469136\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7418016975308642\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.746045524691358\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7507716049382716\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.748070987654321\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7475887345679012\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7466242283950617\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7493248456790124\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7473958333333334\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7475887345679012\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7420910493827161\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7530864197530864\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7492283950617284\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7445023148148148\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7478780864197531\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7527006172839507\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7482638888888888\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7276234567901234\n",
                  "Epoch 2/2, Loss: 0.7563, Last Batch Accuracy: 72.76%\n"
               ]
            }
         ],
         "source": [
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_24.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\52702347.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training9_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training9_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7435378086419753\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5883487654320988\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7266589506172839\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7195216049382716\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.675829475308642\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.6805555555555556\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7027391975308642\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.730516975308642\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7243441358024691\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7288773148148148\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7258873456790124\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7300347222222222\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7374614197530864\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7240547839506173\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7268518518518519\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7318672839506173\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7404513888888888\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7336033950617284\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7405478395061729\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7440200617283951\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7384259259259259\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7395833333333334\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7449845679012346\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7504822530864198\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7377507716049383\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7490354938271605\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7479745370370371\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7499035493827161\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7497106481481481\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7470100308641975\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7427662037037037\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7474922839506173\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7494212962962963\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7433449074074074\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7494212962962963\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7431520061728395\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7491319444444444\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7573302469135802\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7498070987654321\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7415123456790124\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7458526234567902\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7527006172839507\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7388117283950617\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7536651234567902\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7526041666666666\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7466242283950617\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7503858024691358\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7475887345679012\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7447916666666666\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7548225308641975\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.748070987654321\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7510609567901234\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7482638888888888\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7493248456790124\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7553047839506173\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7544367283950617\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7544367283950617\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7483603395061729\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7471064814814815\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7451774691358025\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7477816358024691\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7472029320987654\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7490354938271605\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7518325617283951\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7463348765432098\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7511574074074074\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7486496913580247\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7465277777777778\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7493248456790124\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7466242283950617\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7492283950617284\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7500964506172839\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7497106481481481\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7520254629629629\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7500964506172839\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7526041666666666\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7485532407407407\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7496141975308642\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7638888888888888\n",
                  "Epoch 1/2, Loss: 0.7074, Last Batch Accuracy: 76.39%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7494212962962963\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7511574074074074\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.755883487654321\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7553047839506173\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7527970679012346\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7511574074074074\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7559799382716049\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7492283950617284\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7535686728395061\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7524112654320988\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7549189814814815\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7508680555555556\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7555941358024691\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7553047839506173\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7508680555555556\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7586805555555556\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7556905864197531\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7511574074074074\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7490354938271605\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7525077160493827\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7485532407407407\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7584876543209876\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7564621913580247\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7525077160493827\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7566550925925926\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7543402777777778\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7533757716049383\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7514467592592593\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7580054012345679\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7524112654320988\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7554012345679012\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7497106481481481\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7501929012345679\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7560763888888888\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7552083333333334\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7560763888888888\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7541473765432098\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7518325617283951\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7555941358024691\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7532793209876543\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7557870370370371\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7584876543209876\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7497106481481481\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7483603395061729\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7486496913580247\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7564621913580247\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7454668209876543\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7510609567901234\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7541473765432098\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7529899691358025\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7562692901234568\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7495177469135802\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7553047839506173\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7477816358024691\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7554976851851852\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7475887345679012\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7553047839506173\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7527970679012346\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7489390432098766\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.748070987654321\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7606095679012346\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7493248456790124\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7551118827160493\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7529899691358025\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7526041666666666\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7633101851851852\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7581983024691358\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7532793209876543\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7515432098765432\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7587770061728395\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7537615740740741\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7512538580246914\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7555941358024691\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7587770061728395\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7567515432098766\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7529899691358025\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7504822530864198\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7555941358024691\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.746141975308642\n",
                  "Epoch 2/2, Loss: 0.7141, Last Batch Accuracy: 74.61%\n"
               ]
            }
         ],
         "source": [
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_26.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training6_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Save the model use new names each time tyvm\n",
            "# torch.save(model.state_dict(), 'weights/rnn_4layer_256_18.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Load the model\n",
            "# model = RNN().to(device)\n",
            "# model.load_state_dict(torch.load('weights/rnn_4layer_256_14.pth'))\n",
            "# # model.load_state_dict(torch.load('weights/rnn_4layer_256_6.pth', map_location=torch.device('cpu')))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\414264106.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n"
               ]
            }
         ],
         "source": [
            "test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n",
            "test_dataset.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "test_rubiksdataset = RubiksDataset(test_dataset)\n",
            "test_dataloader = DataLoader(test_rubiksdataset, batch_size = 128)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [],
         "source": [
            "def test(model, test_loader, device):\n",
            "    model.eval()\n",
            "    # test_loss = 0\n",
            "    correct = 0\n",
            "    pred = 0\n",
            "    count = 0\n",
            "    sumofaccuracy = 0\n",
            "    # criterion = torch.nn.CrossEntropyLoss()\n",
            "    with torch.no_grad():\n",
            "        for data, target in test_loader:\n",
            "            for i in range(len(data)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(data[i])):\n",
            "                    output = model(data[i][j].to(device), hidden)\n",
            "                    out, hidden = output[0:19], output[19::]\n",
            "                    # test_loss += criterion(out.to(device), target[i][j].to(device)) / len(data[i]) / len(data)\n",
            "                    # pred = out.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
            "                    # correct += pred.eq(target.view_as(pred)).sum().item()\n",
            "                    # if args.dry_run:\n",
            "                    #     break\n",
            "                    correct += (torch.argmax(out) == target[i][j]).item()\n",
            "                    pred += 1\n",
            "            batch_accuracy = correct/pred\n",
            "\n",
            "    # test_loss /= len(test_loader.dataset)\n",
            "\n",
            "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
            "    #     test_loss, correct, len(test_loader.dataset),\n",
            "    #     100. * correct / len(test_loader.dataset)))\n",
            "            count +=1\n",
            "            print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "            sumofaccuracy += batch_accuracy\n",
            "    print(f\"Total Test accuracy: {sumofaccuracy/count} , for {count} batch in total.\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch 1 accuracy: 0.7932477678571429\n",
                  "Batch 2 accuracy: 0.7918991815476191\n",
                  "Batch 3 accuracy: 0.7912636408730159\n",
                  "Batch 4 accuracy: 0.7904110863095238\n",
                  "Batch 5 accuracy: 0.7897321428571429\n",
                  "Batch 6 accuracy: 0.7889384920634921\n",
                  "Batch 7 accuracy: 0.7885974702380952\n",
                  "Batch 8 accuracy: 0.7879464285714286\n",
                  "Batch 9 accuracy: 0.7868716931216931\n",
                  "Batch 10 accuracy: 0.7865141369047619\n",
                  "Batch 11 accuracy: 0.7856128246753247\n",
                  "Batch 12 accuracy: 0.7850399925595238\n",
                  "Batch 13 accuracy: 0.7844122023809523\n",
                  "Batch 14 accuracy: 0.7837545174319728\n",
                  "Batch 15 accuracy: 0.7830791170634921\n",
                  "Batch 16 accuracy: 0.7827322823660714\n",
                  "Batch 17 accuracy: 0.7821964723389355\n",
                  "Batch 18 accuracy: 0.7819372106481481\n",
                  "Batch 19 accuracy: 0.7813723762531328\n",
                  "Batch 20 accuracy: 0.7808686755952381\n",
                  "Batch 21 accuracy: 0.780501523526077\n",
                  "Batch 22 accuracy: 0.7802311620670995\n",
                  "Batch 23 accuracy: 0.7798629981884058\n",
                  "Batch 24 accuracy: 0.7794053819444444\n",
                  "Batch 25 accuracy: 0.7789508928571428\n",
                  "Batch 26 accuracy: 0.7786136389652014\n",
                  "Batch 27 accuracy: 0.7781635802469136\n",
                  "Batch 28 accuracy: 0.7777855282738095\n",
                  "Batch 29 accuracy: 0.7774944837848933\n",
                  "Batch 30 accuracy: 0.7773220486111111\n",
                  "Batch 31 accuracy: 0.7769807267665131\n",
                  "Batch 32 accuracy: 0.7767450241815477\n",
                  "Batch 33 accuracy: 0.7762981376262627\n",
                  "Batch 34 accuracy: 0.7760772277661064\n",
                  "Batch 35 accuracy: 0.7759646045918367\n",
                  "Batch 36 accuracy: 0.7757781498015873\n",
                  "Batch 37 accuracy: 0.7755087676962676\n",
                  "Batch 38 accuracy: 0.7751360823934837\n",
                  "Batch 39 accuracy: 0.7748278197496947\n",
                  "Batch 40 accuracy: 0.774467540922619\n",
                  "Batch 41 accuracy: 0.7741928898083623\n",
                  "Batch 42 accuracy: 0.7739778202947846\n",
                  "Batch 43 accuracy: 0.7737013773532669\n",
                  "Batch 44 accuracy: 0.7733719730790043\n",
                  "Batch 45 accuracy: 0.773139880952381\n",
                  "Batch 46 accuracy: 0.7728390269151139\n",
                  "Batch 47 accuracy: 0.7724797365754813\n",
                  "Batch 48 accuracy: 0.7721392919146826\n",
                  "Batch 49 accuracy: 0.771877277696793\n",
                  "Batch 50 accuracy: 0.7715308779761905\n",
                  "Batch 51 accuracy: 0.771281950280112\n",
                  "Batch 52 accuracy: 0.7709638993818682\n",
                  "Batch 53 accuracy: 0.7706718890386344\n",
                  "Batch 54 accuracy: 0.770452697861552\n",
                  "Batch 55 accuracy: 0.7701383252164502\n",
                  "Batch 56 accuracy: 0.7698368409863946\n",
                  "Batch 57 accuracy: 0.7696063074352548\n",
                  "Batch 58 accuracy: 0.7694558831075534\n",
                  "Batch 59 accuracy: 0.7690741020984665\n",
                  "Batch 60 accuracy: 0.7688848586309524\n",
                  "Batch 61 accuracy: 0.7686454064207651\n",
                  "Batch 62 accuracy: 0.7684046778993856\n",
                  "Batch 63 accuracy: 0.7681420658541194\n",
                  "Batch 64 accuracy: 0.7678469703311012\n",
                  "Batch 65 accuracy: 0.7675824175824176\n",
                  "Batch 66 accuracy: 0.7672089195526696\n",
                  "Batch 67 accuracy: 0.7670603455934613\n",
                  "Batch 68 accuracy: 0.7667656906512605\n",
                  "Batch 69 accuracy: 0.7664647493961353\n",
                  "Batch 70 accuracy: 0.7661471619897959\n",
                  "Batch 71 accuracy: 0.7657481346411804\n",
                  "Batch 72 accuracy: 0.7654131531084656\n",
                  "Batch 73 accuracy: 0.7650504015818657\n",
                  "Batch 74 accuracy: 0.764764066521879\n",
                  "Batch 75 accuracy: 0.7644196428571428\n",
                  "Batch 76 accuracy: 0.7640414512844611\n",
                  "Batch 77 accuracy: 0.7636754986085343\n",
                  "Batch 78 accuracy: 0.7630864144536019\n",
                  "Batch 79 accuracy: 0.7629952380952381\n",
                  "Total Test accuracy: 0.7753876246157533 , for 79 batch in total.\n"
               ]
            }
         ],
         "source": [
            "test(model, test_dataloader, device=device)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "metadata": {},
         "outputs": [],
         "source": [
            "# shawns stuff"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # split data into features\n",
            "# targets_numpy = train.label.values\n",
            "# features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
            "\n",
            "# # train test split. Size of train data is 80% and size of test data is 20%. \n",
            "# features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
            "#                                                                              targets_numpy,\n",
            "#                                                                              test_size = 0.2,\n",
            "#                                                                              random_state = 42) \n",
            "\n",
            "# # create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
            "# featuresTrain = torch.from_numpy(features_train)\n",
            "# targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
            "\n",
            "# # create feature and targets tensor for test set.\n",
            "# featuresTest = torch.from_numpy(features_test)\n",
            "# targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
            "\n",
            "# # batch_size, epoch and iteration\n",
            "# batch_size = 100\n",
            "# n_iters = 10000\n",
            "# num_epochs = n_iters / (len(features_train) / batch_size)\n",
            "# num_epochs = int(num_epochs)\n",
            "\n",
            "# # Pytorch train and test sets\n",
            "# train = TensorDataset(featuresTrain,targetsTrain)\n",
            "# test = TensorDataset(featuresTest,targetsTest)\n",
            "\n",
            "# # data loader\n",
            "# train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
            "# test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
            "\n",
            "# # visualize one of the images in data set\n",
            "# plt.imshow(features_numpy[10].reshape(28,28))\n",
            "# plt.axis(\"off\")\n",
            "# plt.title(str(targets_numpy[10]))\n",
            "# plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Create RNN Model\n",
            "# class RNNModel(nn.Module):\n",
            "#     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
            "#         super(RNNModel, self).__init__()\n",
            "        \n",
            "#         # Number of hidden dimensions\n",
            "#         self.hidden_dim = hidden_dim\n",
            "        \n",
            "#         # Number of hidden layers\n",
            "#         self.layer_dim = layer_dim\n",
            "        \n",
            "#         # RNN\n",
            "#         self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
            "        \n",
            "#         # Readout layer\n",
            "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
            "    \n",
            "#     def forward(self, x):\n",
            "        \n",
            "#         # Initialize hidden state with zeros\n",
            "#         h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
            "            \n",
            "#         # One time step\n",
            "#         out, hn = self.rnn(x, h0)\n",
            "#         out = self.fc(out[:, -1, :]) \n",
            "#         return out\n",
            "\n",
            "# # batch_size, epoch and iteration\n",
            "# batch_size = 100\n",
            "# n_iters = 8000\n",
            "# num_epochs = n_iters / (len(features_train) / batch_size)\n",
            "# num_epochs = int(num_epochs)\n",
            "\n",
            "# # Pytorch train and test sets\n",
            "# train = TensorDataset(featuresTrain,targetsTrain)\n",
            "# test = TensorDataset(featuresTest,targetsTest)\n",
            "\n",
            "# # data loader\n",
            "# train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
            "# test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
            "    \n",
            "# # Create RNN\n",
            "# input_dim = 28    # input dimension\n",
            "# hidden_dim = 100  # hidden layer dimension\n",
            "# layer_dim = 1     # number of hidden layers\n",
            "# output_dim = 10   # output dimension\n",
            "\n",
            "# model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
            "\n",
            "# # Cross Entropy Loss \n",
            "# error = nn.CrossEntropyLoss()\n",
            "\n",
            "# # SGD Optimizer\n",
            "# learning_rate = 0.05\n",
            "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 42,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Training model\n",
            "# seq_dim = 28  \n",
            "# loss_list = []\n",
            "# iteration_list = []\n",
            "# accuracy_list = []\n",
            "# count = 0\n",
            "# for epoch in range(num_epochs):\n",
            "#     for i, (images, labels) in enumerate(train_loader):\n",
            "\n",
            "#         train  = Variable(images.view(-1, seq_dim, input_dim))\n",
            "#         labels = Variable(labels )\n",
            "            \n",
            "#         # Clear gradients\n",
            "#         optimizer.zero_grad()\n",
            "        \n",
            "#         # Forward propagation\n",
            "#         outputs = model(train)\n",
            "        \n",
            "#         # Calculate softmax and ross entropy loss\n",
            "#         loss = error(outputs, labels)\n",
            "        \n",
            "#         # Calculating gradients\n",
            "#         loss.backward()\n",
            "        \n",
            "#         # Update parameters\n",
            "#         optimizer.step()\n",
            "        \n",
            "#         count += 1\n",
            "        \n",
            "#         if count % 250 == 0:\n",
            "#             # Calculate Accuracy         \n",
            "#             correct = 0\n",
            "#             total = 0\n",
            "#             # Iterate through test dataset\n",
            "#             for images, labels in test_loader:\n",
            "#                 images = Variable(images.view(-1, seq_dim, input_dim))\n",
            "                \n",
            "#                 # Forward propagation\n",
            "#                 outputs = model(images)\n",
            "                \n",
            "#                 # Get predictions from the maximum value\n",
            "#                 predicted = torch.max(outputs.data, 1)[1]\n",
            "                \n",
            "#                 # Total number of labels\n",
            "#                 total += labels.size(0)\n",
            "                \n",
            "#                 correct += (predicted == labels).sum()\n",
            "            \n",
            "#             accuracy = 100 * correct / float(total)\n",
            "            \n",
            "#             # store loss and iteration\n",
            "#             loss_list.append(loss.data)\n",
            "#             iteration_list.append(count)\n",
            "#             accuracy_list.append(accuracy)\n",
            "#             if count % 500 == 0:\n",
            "#                 # Print Loss\n",
            "#                 print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # visualization loss \n",
            "# plt.plot(iteration_list,loss_list)\n",
            "# plt.xlabel(\"Number of iteration\")\n",
            "# plt.ylabel(\"Loss\")\n",
            "# plt.title(\"RNN: Loss vs Number of iteration\")\n",
            "# plt.show()\n",
            "\n",
            "# # visualization accuracy \n",
            "# plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
            "# plt.xlabel(\"Number of iteration\")\n",
            "# plt.ylabel(\"Accuracy\")\n",
            "# plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
            "# plt.savefig('graph.png')\n",
            "# plt.show()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
