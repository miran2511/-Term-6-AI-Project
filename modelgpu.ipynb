{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import Libraries\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.autograd import Variable\n",
            "from sklearn.model_selection import train_test_split\n",
            "from torch.utils.data import DataLoader, TensorDataset, Dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cuda\n"
               ]
            }
         ],
         "source": [
            "# Use GPU if available, else use CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training0_sort.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df.info()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# display datatypes\n",
            "# df.dtypes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df.dtypes.value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "# run this\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training5_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# df.iloc[1,1:].values\n",
            "# type(df.iloc[1,:].values)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Our custom Dataset object\n",
            "class RubiksDataset(Dataset):\n",
            "    def __init__(self, df):\n",
            "        self.df = df\n",
            "        move_dict = {\"#\":0, \"U\":1, \"U'\":2, \"U2\":3, \"D\":4, \"D'\":5, \"D2\":6, \"L\":7, \"L'\":8, \"L2\":9, \"R\":10, \n",
            "                     \"R'\":11, \"R2\":12, \"F\":13, \"F'\":14, \"F2\":15, \"B\":16, \"B'\":17, \"B2\":18}\n",
            "        # list of list, where inner list is an entire sequence.\n",
            "        self.states = [] #is now a list of list of list :D\n",
            "        self.moves = [] #list of list\n",
            "\n",
            "        for i in range(len(df)):\n",
            "            statelist = []\n",
            "            movelist = []\n",
            "            statemoves = df.iloc[i,1:]\n",
            "            for line in statemoves:\n",
            "                split = line.split(\",\")\n",
            "                # state_as_int = int(split[0].replace(\" \",\"\"))/(10**54)\n",
            "                state_as_str_list = split[0].split(\" \")\n",
            "                state_as_int_list = [int(i) for i in state_as_str_list]\n",
            "                # above sets the input states to int values instead of string\n",
            "                # below sets the string move into an int value,\n",
            "                move_as_int = move_dict.get(split[1])\n",
            "\n",
            "                statelist.append(state_as_int_list)\n",
            "                movelist.append(move_as_int)\n",
            "            self.states.append(statelist)\n",
            "            self.moves.append(movelist)\n",
            "\n",
            "\n",
            "        \n",
            "    def __len__(self):\n",
            "        return len(self.moves)\n",
            "        \n",
            "    def __getitem__(self, index):\n",
            "        # inputs = torch.tensor(self.inputs[index]).float()\n",
            "        # outputs = torch.tensor(self.outputs[index]).float()\n",
            "        # print(self.states[index])\n",
            "        inputs = torch.tensor(self.states[index]) # list of list, each index is a state vector\n",
            "        outputs = torch.tensor(self.moves[index]) # list, each index is the move set of that sequence(index)\n",
            "        return inputs, outputs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training5_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "# seqcount = 0\n",
            "# for inputs, outputs in dataloader:\n",
            "#     seqcount +=1\n",
            "#     print(outputs)\n",
            "#     # for i in outputs:\n",
            "#     #     print(i)\n",
            "#     print(seqcount)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "class RNN(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(RNN, self).__init__()\n",
            "        self.layers = torch.nn.Sequential(torch.nn.Linear(108, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 256),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(256, 128),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(128, 73))\n",
            "        \n",
            "    def forward(self, inputs, hidden):\n",
            "        # combined = torch.tensor([inputs, hidden]).to(inputs.device)\n",
            "        # print(inputs.shape)\n",
            "        # print(hidden.shape)\n",
            "        combined = torch.cat([inputs, hidden]).to(inputs.device)\n",
            "        out = self.layers(combined)\n",
            "        return out"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Sequential(\n",
                  "  (0): Linear(in_features=108, out_features=256, bias=True)\n",
                  "  (1): ReLU()\n",
                  "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
                  "  (3): ReLU()\n",
                  "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
                  "  (5): ReLU()\n",
                  "  (6): Linear(in_features=128, out_features=73, bias=True)\n",
                  ")\n"
               ]
            }
         ],
         "source": [
            "# model = RNN().to(device)\n",
            "# print(model.layers)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "def train(model, dataloader, num_epochs, learning_rate, device):\n",
            "    criterion = torch.nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
            "    # hidden = torch.tensor([0]).to(device)\n",
            "    # hidden= torch.zeros(1, 81, 54).to(device)\n",
            "    for epoch in range(num_epochs):\n",
            "        count = 0\n",
            "        loss = 0\n",
            "\n",
            "        \n",
            "        # optimizer.zero_grad()\n",
            "        for inputs, targets in dataloader:\n",
            "            # inputs = inputs.permute(1,0,2)\n",
            "            # need another loop inside.\n",
            "            correct = 0\n",
            "            pred = 0\n",
            "            \n",
            "            # reset hidden here\n",
            "            loss = 0\n",
            "            optimizer.zero_grad()\n",
            "            # \n",
            "            for i in range(len(inputs)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(inputs[i])):\n",
            "                    outputs = model(inputs[i][j].to(device), hidden)\n",
            "                    out, hidden = outputs[0:19], outputs[19::]\n",
            "                    # print(out.shape)\n",
            "                    # print(hidden.shape)\n",
            "                    # print(targets[i][j].shape)\n",
            "\n",
            "                    # print((torch.argmax(out) == targets[i][j]).item())\n",
            "                    correct += (torch.argmax(out) == targets[i][j]).item()\n",
            "                    pred += 1\n",
            "                    loss += criterion(out.to(device), targets[i][j].to(device)) / len(inputs[i]) / len(inputs)\n",
            "                # print(loss)\n",
            "            batch_accuracy = correct/pred\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "            count +=1\n",
            "            print(f\"Batch number: {count}\")\n",
            "            print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "        \n",
            "        # loss /= len(inputs)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        #     outputs = model(inputs.to(device), hidden)\n",
            "        #     out, hidden = outputs[0], outputs[1]\n",
            "        #     loss += criterion(out.to(device), targets.to(device))\n",
            "        # loss /= len(dataloader)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Last Batch Accuracy: {batch_accuracy*100:.2f}%\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model = RNN().to(device)\n",
            "model.load_state_dict(torch.load('weights/rnn_4layer_256_37.pth'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_19860\\299646355.py:1: DtypeWarning: Columns (68,69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training0_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training0_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7511574074074074\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7559799382716049\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7527970679012346\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7520254629629629\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7524112654320988\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.7592592592592593\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7594521604938271\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7555941358024691\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.7546296296296297\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7541473765432098\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7568479938271605\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7546296296296297\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7543402777777778\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7554012345679012\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.7535686728395061\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7510609567901234\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7588734567901234\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7546296296296297\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7554976851851852\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7533757716049383\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7559799382716049\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7555941358024691\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7544367283950617\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7533757716049383\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7546296296296297\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7566550925925926\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7530864197530864\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7582947530864198\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7586805555555556\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7553047839506173\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7607060185185185\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7575231481481481\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7651427469135802\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7520254629629629\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7562692901234568\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7547260802469136\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7567515432098766\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7532793209876543\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7567515432098766\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7557870370370371\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7543402777777778\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7579089506172839\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7562692901234568\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7562692901234568\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7603202160493827\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.751929012345679\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7632137345679012\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7530864197530864\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7567515432098766\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7513503086419753\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7500964506172839\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7593557098765432\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7542438271604939\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7543402777777778\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7513503086419753\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7508680555555556\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7575231481481481\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7556905864197531\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7634066358024691\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7550154320987654\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7531828703703703\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7560763888888888\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7653356481481481\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7594521604938271\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7534722222222222\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7530864197530864\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7475887345679012\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7581018518518519\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7628279320987654\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7477816358024691\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.753954475308642\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7554012345679012\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.753954475308642\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7582947530864198\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7495177469135802\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7600308641975309\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7603202160493827\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7555941358024691\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7638888888888888\n",
                  "Epoch 1/1, Loss: 0.7060, Last Batch Accuracy: 76.39%\n"
               ]
            }
         ],
         "source": [
            "# Train the model\n",
            "# model = RNN().to(device)\n",
            "train(model, dataloader, num_epochs = 1, learning_rate = 0.0001, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_x.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\1325915394.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training7_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training1_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_x.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_3552\\1852383510.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training8_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training8_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "train(model, dataloader, num_epochs = 2, learning_rate = 0.0005, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_24.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# trainhere"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_19860\\52702347.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training9_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training9_sort.csv')\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.7663966049382716\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.7642746913580247\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.7643711419753086\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.7601273148148148\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.7565586419753086\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.761766975308642\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.7588734567901234\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.7650462962962963\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.761766975308642\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.7645640432098766\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.7602237654320988\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.7684220679012346\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.7666859567901234\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.7611882716049383\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.759741512345679\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.7641782407407407\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.7660108024691358\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.7643711419753086\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.7692901234567902\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.7632137345679012\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.7651427469135802\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.7608024691358025\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.7622492283950617\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.7678433641975309\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.7643711419753086\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.7600308641975309\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.7561728395061729\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.7633101851851852\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.7623456790123457\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.7676504629629629\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.7599344135802469\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.7663966049382716\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.7679398148148148\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.7650462962962963\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.7689043209876543\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.7687114197530864\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.7655285493827161\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.7681327160493827\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.7605131172839507\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.7666859567901234\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.7690007716049383\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.7646604938271605\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.7701581790123457\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.7665895061728395\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.7580054012345679\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.7614776234567902\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.7653356481481481\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.7567515432098766\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.7655285493827161\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.7653356481481481\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.7649498456790124\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.7667824074074074\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.7628279320987654\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.7728587962962963\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.7563657407407407\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.7660108024691358\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.7590663580246914\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.7641782407407407\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.7662037037037037\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.7637924382716049\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.7668788580246914\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.7622492283950617\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.7648533950617284\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.7646604938271605\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.7606095679012346\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.7638888888888888\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.7585841049382716\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.7630208333333334\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.7627314814814815\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.7666859567901234\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.7668788580246914\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.7608024691358025\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.7660108024691358\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.7665895061728395\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.7638888888888888\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.7698688271604939\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.7620563271604939\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.7649498456790124\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.7731481481481481\n",
                  "Epoch 1/1, Loss: 0.6451, Last Batch Accuracy: 77.31%\n"
               ]
            }
         ],
         "source": [
            "train(model, dataloader, num_epochs = 1, learning_rate = 0.0001, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_4layer_256_37.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.read_csv('dataset/training6_sort.csv')\n",
            "# df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "# dataset = RubiksDataset(df)\n",
            "# # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "# dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Save the model use new names each time tyvm\n",
            "# torch.save(model.state_dict(), 'weights/rnn_4layer_256_18.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Load the model\n",
            "# model = RNN().to(device)\n",
            "# model.load_state_dict(torch.load('weights/rnn_4layer_256_14.pth'))\n",
            "# # model.load_state_dict(torch.load('weights/rnn_4layer_256_6.pth', map_location=torch.device('cpu')))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\samje\\AppData\\Local\\Temp\\ipykernel_1812\\414264106.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n"
               ]
            }
         ],
         "source": [
            "test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n",
            "test_dataset.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "test_rubiksdataset = RubiksDataset(test_dataset)\n",
            "test_dataloader = DataLoader(test_rubiksdataset, batch_size = 128)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "# def test(model, test_loader, device):\n",
            "#     model.eval()\n",
            "#     # test_loss = 0\n",
            "#     correct = 0\n",
            "#     pred = 0\n",
            "#     count = 0\n",
            "#     sumofaccuracy = 0\n",
            "#     # criterion = torch.nn.CrossEntropyLoss()\n",
            "#     with torch.no_grad():\n",
            "#         for data, target in test_loader:\n",
            "#             for i in range(len(data)):\n",
            "#                 hidden= torch.zeros(54).to(device)\n",
            "#                 for j in range(len(data[i])):\n",
            "#                     output = model(data[i][j].to(device), hidden)\n",
            "#                     out, hidden = output[0:19], output[19::]\n",
            "#                     # test_loss += criterion(out.to(device), target[i][j].to(device)) / len(data[i]) / len(data)\n",
            "#                     # pred = out.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
            "#                     # correct += pred.eq(target.view_as(pred)).sum().item()\n",
            "#                     # if args.dry_run:\n",
            "#                     #     break\n",
            "#                     correct += (torch.argmax(out) == target[i][j]).item()\n",
            "#                     pred += 1\n",
            "#             batch_accuracy = correct/pred\n",
            "\n",
            "#     # test_loss /= len(test_loader.dataset)\n",
            "\n",
            "#     # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
            "#     #     test_loss, correct, len(test_loader.dataset),\n",
            "#     #     100. * correct / len(test_loader.dataset)))\n",
            "#             count +=1\n",
            "#             print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "#             sumofaccuracy += batch_accuracy\n",
            "#     print(f\"Total Test accuracy: {sumofaccuracy/count} , for {count} batch in total.\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "def test(model, test_loader, device):\n",
            "    model.eval()\n",
            "    # test_loss = 0\n",
            "    correct = 0\n",
            "    pred = 0\n",
            "    count = 0\n",
            "    sumofaccuracy = 0\n",
            "\n",
            "    # Number of times a move was predicted as the following and was correct\n",
            "    correct_pred_move_count = {\"#\": 0, \"U\": 0, \"U'\": 0, \"U2\": 0, \"D\": 0, \"D'\": 0, \"D2\": 0, \"L\": 0, \"L'\": 0, \"L2\": 0, \"R\": 0, \n",
            "                     \"R'\": 0, \"R2\": 0, \"F\": 0, \"F'\": 0, \"F2\": 0, \"B\": 0, \"B'\": 0, \"B2\": 0}\n",
            "    \n",
            "    # Number of times this move was the correct move\n",
            "    true_move_count = {\"#\": 0, \"U\": 0, \"U'\": 0, \"U2\": 0, \"D\": 0, \"D'\": 0, \"D2\": 0, \"L\": 0, \"L'\": 0, \"L2\": 0, \"R\": 0, \n",
            "                     \"R'\": 0, \"R2\": 0, \"F\": 0, \"F'\": 0, \"F2\": 0, \"B\": 0, \"B'\": 0, \"B2\": 0}\n",
            "\n",
            "    move_mapping = [\"#\", \"U\", \"U'\", \"U2\", \"D\", \"D'\", \"D2\", \"L\", \"L'\", \"L2\", \"R\", \n",
            "                     \"R'\", \"R2\", \"F\", \"F'\", \"F2\", \"B\", \"B'\", \"B2\"]\n",
            "\n",
            "    # criterion = torch.nn.CrossEntropyLoss()\n",
            "    with torch.no_grad():\n",
            "        for data, target in test_loader:\n",
            "            for i in range(len(data)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(data[i])):\n",
            "                    output = model(data[i][j].to(device), hidden)\n",
            "                    out, hidden = output[0:19], output[19::]\n",
            "                    # test_loss += criterion(out.to(device), target[i][j].to(device)) / len(data[i]) / len(data)\n",
            "                    # pred = out.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
            "                    # correct += pred.eq(target.view_as(pred)).sum().item()\n",
            "                    # if args.dry_run:\n",
            "                    #     break\n",
            "                    pred_move = torch.argmax(out)\n",
            "                    correct += (pred_move == target[i][j]).item()\n",
            "                    pred += 1\n",
            "\n",
            "                    if (pred_move == target[i][j]).item():\n",
            "                        correct_pred_move_count[move_mapping[torch.argmax(out).item()]] += 1\n",
            "                    true_move_count[move_mapping[target[i][j].item()]] += 1\n",
            "            # print(correct_pred_move_count)\n",
            "            # print(true_move_count)\n",
            "            batch_accuracy = correct/pred\n",
            "\n",
            "    # test_loss /= len(test_loader.dataset)\n",
            "\n",
            "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
            "    #     test_loss, correct, len(test_loader.dataset),\n",
            "    #     100. * correct / len(test_loader.dataset)))\n",
            "            count +=1\n",
            "            print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "            sumofaccuracy += batch_accuracy\n",
            "            \n",
            "    print(f\"Total Test accuracy: {sumofaccuracy/count} , for {count} batch in total.\")\n",
            "    true_prediction_accuracy_dict = {move: f'{correct_pred_move_count[move]/true_move_count[move]*100:.2f}%' for move in move_mapping}\n",
            "    print(f\"True prediction accuracies: {true_prediction_accuracy_dict}\")\n",
            "    print(correct_pred_move_count)\n",
            "    print(true_move_count)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch 1 accuracy: 0.8017113095238095\n",
                  "Batch 2 accuracy: 0.7994791666666666\n",
                  "Batch 3 accuracy: 0.7979910714285714\n",
                  "Batch 4 accuracy: 0.7975260416666666\n",
                  "Batch 5 accuracy: 0.7967447916666667\n",
                  "Batch 6 accuracy: 0.7960844494047619\n",
                  "Batch 7 accuracy: 0.7960512329931972\n",
                  "Batch 8 accuracy: 0.7955845424107143\n",
                  "Batch 9 accuracy: 0.7946118551587301\n",
                  "Batch 10 accuracy: 0.7941313244047619\n",
                  "Batch 11 accuracy: 0.793171672077922\n",
                  "Batch 12 accuracy: 0.7927207341269841\n",
                  "Batch 13 accuracy: 0.792167467948718\n",
                  "Batch 14 accuracy: 0.7915869472789115\n",
                  "Batch 15 accuracy: 0.7910280257936508\n",
                  "Batch 16 accuracy: 0.7906552269345238\n",
                  "Batch 17 accuracy: 0.790063681722689\n",
                  "Batch 18 accuracy: 0.7897393766534392\n",
                  "Batch 19 accuracy: 0.7893317277568922\n",
                  "Batch 20 accuracy: 0.7888997395833334\n",
                  "Batch 21 accuracy: 0.7886506164965986\n",
                  "Batch 22 accuracy: 0.7882846320346321\n",
                  "Batch 23 accuracy: 0.7880556094720497\n",
                  "Batch 24 accuracy: 0.7875279017857143\n",
                  "Batch 25 accuracy: 0.7870833333333334\n",
                  "Batch 26 accuracy: 0.7868267799908425\n",
                  "Batch 27 accuracy: 0.7864307760141094\n",
                  "Batch 28 accuracy: 0.786175993835034\n",
                  "Batch 29 accuracy: 0.7858970905172413\n",
                  "Batch 30 accuracy: 0.7857669890873016\n",
                  "Batch 31 accuracy: 0.785447268625192\n",
                  "Batch 32 accuracy: 0.7852056594122023\n",
                  "Batch 33 accuracy: 0.7847814078282829\n",
                  "Batch 34 accuracy: 0.784609156162465\n",
                  "Batch 35 accuracy: 0.7844972363945578\n",
                  "Batch 36 accuracy: 0.784314029431217\n",
                  "Batch 37 accuracy: 0.7840653153153153\n",
                  "Batch 38 accuracy: 0.7836779448621554\n",
                  "Batch 39 accuracy: 0.7833175938644689\n",
                  "Batch 40 accuracy: 0.7829194568452381\n",
                  "Batch 41 accuracy: 0.7825974520905923\n",
                  "Batch 42 accuracy: 0.7823926445578231\n",
                  "Batch 43 accuracy: 0.7820437949889258\n",
                  "Batch 44 accuracy: 0.7817002333603896\n",
                  "Batch 45 accuracy: 0.7814566798941799\n",
                  "Batch 46 accuracy: 0.7811994532867494\n",
                  "Batch 47 accuracy: 0.7808799550405269\n",
                  "Batch 48 accuracy: 0.7805989583333334\n",
                  "Batch 49 accuracy: 0.7803522078474247\n",
                  "Batch 50 accuracy: 0.7800111607142857\n",
                  "Batch 51 accuracy: 0.7798239087301587\n",
                  "Batch 52 accuracy: 0.7795454870650184\n",
                  "Batch 53 accuracy: 0.7792881008535489\n",
                  "Batch 54 accuracy: 0.7790471367945326\n",
                  "Batch 55 accuracy: 0.7787861877705627\n",
                  "Batch 56 accuracy: 0.7784697863520408\n",
                  "Batch 57 accuracy: 0.7782705461570593\n",
                  "Batch 58 accuracy: 0.7781375076970444\n",
                  "Batch 59 accuracy: 0.7777551831113801\n",
                  "Batch 60 accuracy: 0.7775778149801588\n",
                  "Batch 61 accuracy: 0.777406262197502\n",
                  "Batch 62 accuracy: 0.7771682387672811\n",
                  "Batch 63 accuracy: 0.7769613921957672\n",
                  "Batch 64 accuracy: 0.7766709100632441\n",
                  "Batch 65 accuracy: 0.7764408768315019\n",
                  "Batch 66 accuracy: 0.7761008522727273\n",
                  "Batch 67 accuracy: 0.7759597659026297\n",
                  "Batch 68 accuracy: 0.7757079394257703\n",
                  "Batch 69 accuracy: 0.7754243228088337\n",
                  "Batch 70 accuracy: 0.7751142644557824\n",
                  "Batch 71 accuracy: 0.7747356535043595\n",
                  "Batch 72 accuracy: 0.7744192294973545\n",
                  "Batch 73 accuracy: 0.7741076524787998\n",
                  "Batch 74 accuracy: 0.7737982122747747\n",
                  "Batch 75 accuracy: 0.7734722222222222\n",
                  "Batch 76 accuracy: 0.7730985177788221\n",
                  "Batch 77 accuracy: 0.772730896335807\n",
                  "Batch 78 accuracy: 0.7721413785866911\n",
                  "Batch 79 accuracy: 0.7720738095238096\n",
                  "Total Test accuracy: 0.7837504021931515 , for 79 batch in total.\n",
                  "True prediction accuracies: {'#': '100.00%', 'U': '73.41%', \"U'\": '68.96%', 'U2': '47.62%', 'D': '60.70%', \"D'\": '61.35%', 'D2': '45.18%', 'L': '80.28%', \"L'\": '81.14%', 'L2': '68.94%', 'R': '67.23%', \"R'\": '70.78%', 'R2': '46.23%', 'F': '71.14%', \"F'\": '78.33%', 'F2': '40.76%', 'B': '73.31%', \"B'\": '73.64%', 'B2': '40.03%'}\n",
                  "{'#': 222581, 'U': 68774, \"U'\": 51699, 'U2': 24976, 'D': 5745, \"D'\": 5323, 'D2': 3301, 'L': 32644, \"L'\": 32227, 'L2': 3669, 'R': 24220, \"R'\": 26448, 'R2': 4029, 'F': 36061, \"F'\": 39671, 'F2': 5136, 'B': 27829, \"B'\": 30090, 'B2': 4119}\n",
                  "{'#': 222584, 'U': 93685, \"U'\": 74970, 'U2': 52451, 'D': 9464, \"D'\": 8676, 'D2': 7307, 'L': 40665, \"L'\": 39718, 'L2': 5322, 'R': 36027, \"R'\": 37365, 'R2': 8716, 'F': 50690, \"F'\": 50646, 'F2': 12602, 'B': 37962, \"B'\": 40860, 'B2': 10290}\n"
               ]
            }
         ],
         "source": [
            "test(model, test_dataloader, device=device)\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
