{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import Libraries\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.autograd import Variable\n",
            "from sklearn.model_selection import train_test_split\n",
            "from torch.utils.data import DataLoader, TensorDataset, Dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cpu\n"
               ]
            }
         ],
         "source": [
            "# Use GPU if available, else use CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\joen\\AppData\\Local\\Temp\\ipykernel_25596\\1228740871.py:1: DtypeWarning: Columns (68,69,70,71,72,73,74,75,76,77,78,79,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv('dataset/training0_sort.csv')\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_csv('dataset/training0_sort.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "<class 'pandas.core.frame.DataFrame'>\n",
                  "RangeIndex: 10000 entries, 0 to 9999\n",
                  "Data columns (total 82 columns):\n",
                  " #   Column  Non-Null Count  Dtype \n",
                  "---  ------  --------------  ----- \n",
                  " 0   sol     10000 non-null  int64 \n",
                  " 1   0       10000 non-null  object\n",
                  " 2   1       10000 non-null  object\n",
                  " 3   2       10000 non-null  object\n",
                  " 4   3       10000 non-null  object\n",
                  " 5   4       10000 non-null  object\n",
                  " 6   5       10000 non-null  object\n",
                  " 7   6       10000 non-null  object\n",
                  " 8   7       10000 non-null  object\n",
                  " 9   8       10000 non-null  object\n",
                  " 10  9       10000 non-null  object\n",
                  " 11  10      10000 non-null  object\n",
                  " 12  11      10000 non-null  object\n",
                  " 13  12      10000 non-null  object\n",
                  " 14  13      10000 non-null  object\n",
                  " 15  14      10000 non-null  object\n",
                  " 16  15      10000 non-null  object\n",
                  " 17  16      10000 non-null  object\n",
                  " 18  17      10000 non-null  object\n",
                  " 19  18      10000 non-null  object\n",
                  " 20  19      10000 non-null  object\n",
                  " 21  20      10000 non-null  object\n",
                  " 22  21      10000 non-null  object\n",
                  " 23  22      10000 non-null  object\n",
                  " 24  23      10000 non-null  object\n",
                  " 25  24      10000 non-null  object\n",
                  " 26  25      10000 non-null  object\n",
                  " 27  26      10000 non-null  object\n",
                  " 28  27      10000 non-null  object\n",
                  " 29  28      10000 non-null  object\n",
                  " 30  29      10000 non-null  object\n",
                  " 31  30      10000 non-null  object\n",
                  " 32  31      10000 non-null  object\n",
                  " 33  32      10000 non-null  object\n",
                  " 34  33      10000 non-null  object\n",
                  " 35  34      10000 non-null  object\n",
                  " 36  35      10000 non-null  object\n",
                  " 37  36      10000 non-null  object\n",
                  " 38  37      10000 non-null  object\n",
                  " 39  38      9999 non-null   object\n",
                  " 40  39      9999 non-null   object\n",
                  " 41  40      9997 non-null   object\n",
                  " 42  41      9992 non-null   object\n",
                  " 43  42      9987 non-null   object\n",
                  " 44  43      9981 non-null   object\n",
                  " 45  44      9974 non-null   object\n",
                  " 46  45      9967 non-null   object\n",
                  " 47  46      9954 non-null   object\n",
                  " 48  47      9937 non-null   object\n",
                  " 49  48      9903 non-null   object\n",
                  " 50  49      9865 non-null   object\n",
                  " 51  50      9823 non-null   object\n",
                  " 52  51      9753 non-null   object\n",
                  " 53  52      9654 non-null   object\n",
                  " 54  53      9524 non-null   object\n",
                  " 55  54      9342 non-null   object\n",
                  " 56  55      9117 non-null   object\n",
                  " 57  56      8823 non-null   object\n",
                  " 58  57      8433 non-null   object\n",
                  " 59  58      7952 non-null   object\n",
                  " 60  59      7394 non-null   object\n",
                  " 61  60      6735 non-null   object\n",
                  " 62  61      6012 non-null   object\n",
                  " 63  62      5249 non-null   object\n",
                  " 64  63      4484 non-null   object\n",
                  " 65  64      3686 non-null   object\n",
                  " 66  65      3009 non-null   object\n",
                  " 67  66      2356 non-null   object\n",
                  " 68  67      1795 non-null   object\n",
                  " 69  68      1304 non-null   object\n",
                  " 70  69      922 non-null    object\n",
                  " 71  70      652 non-null    object\n",
                  " 72  71      459 non-null    object\n",
                  " 73  72      313 non-null    object\n",
                  " 74  73      199 non-null    object\n",
                  " 75  74      119 non-null    object\n",
                  " 76  75      79 non-null     object\n",
                  " 77  76      50 non-null     object\n",
                  " 78  77      29 non-null     object\n",
                  " 79  78      12 non-null     object\n",
                  " 80  79      5 non-null      object\n",
                  " 81  80      2 non-null      object\n",
                  "dtypes: int64(1), object(81)\n",
                  "memory usage: 6.3+ MB\n"
               ]
            }
         ],
         "source": [
            "df.info()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "sol     int64\n",
                     "0      object\n",
                     "1      object\n",
                     "2      object\n",
                     "3      object\n",
                     "        ...  \n",
                     "76     object\n",
                     "77     object\n",
                     "78     object\n",
                     "79     object\n",
                     "80     object\n",
                     "Length: 82, dtype: object"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# display datatypes\n",
            "df.dtypes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "object    81\n",
                     "int64      1\n",
                     "dtype: int64"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df.dtypes.value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# run this\n",
            "df.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Prepare Dataset\n",
            "# load data\n",
            "# df = pd.read_csv('dataset/training0_sort.csv',dtype = np.float32)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# df.iloc[1,1:].values\n",
            "# type(df.iloc[1,:].values)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Our custom Dataset object\n",
            "class RubiksDataset(Dataset):\n",
            "    def __init__(self, df):\n",
            "        self.df = df\n",
            "        move_dict = {\"#\":0, \"U\":1, \"U'\":2, \"U2\":3, \"D\":4, \"D'\":5, \"D2\":6, \"L\":7, \"L'\":8, \"L2\":9, \"R\":10, \n",
            "                     \"R'\":11, \"R2\":12, \"F\":13, \"F'\":14, \"F2\":15, \"B\":16, \"B'\":17, \"B2\":18}\n",
            "        # list of list, where inner list is an entire sequence.\n",
            "        self.states = [] #is now a list of list of list :D\n",
            "        self.moves = [] #list of list\n",
            "\n",
            "        for i in range(len(df)):\n",
            "            statelist = []\n",
            "            movelist = []\n",
            "            statemoves = df.iloc[i,1:]\n",
            "            for line in statemoves:\n",
            "                split = line.split(\",\")\n",
            "                # state_as_int = int(split[0].replace(\" \",\"\"))/(10**54)\n",
            "                state_as_str_list = split[0].split(\" \")\n",
            "                state_as_int_list = [int(i) for i in state_as_str_list]\n",
            "                # above sets the input states to int values instead of string\n",
            "                # below sets the string move into an int value,\n",
            "                move_as_int = move_dict.get(split[1])\n",
            "\n",
            "                statelist.append(state_as_int_list)\n",
            "                movelist.append(move_as_int)\n",
            "            self.states.append(statelist)\n",
            "            self.moves.append(movelist)\n",
            "\n",
            "\n",
            "        \n",
            "    def __len__(self):\n",
            "        return len(self.moves)\n",
            "        \n",
            "    def __getitem__(self, index):\n",
            "        # inputs = torch.tensor(self.inputs[index]).float()\n",
            "        # outputs = torch.tensor(self.outputs[index]).float()\n",
            "        # print(self.states[index])\n",
            "        inputs = torch.tensor(self.states[index]) # list of list, each index is a state vector\n",
            "        outputs = torch.tensor(self.moves[index]) # list, each index is the move set of that sequence(index)\n",
            "        return inputs, outputs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "dataset = RubiksDataset(df)\n",
            "# dataloader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
            "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "seqcount = 0\n",
            "for inputs, outputs in dataloader:\n",
            "    seqcount +=1\n",
            "    print(outputs)\n",
            "    # for i in outputs:\n",
            "    #     print(i)\n",
            "    print(seqcount)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "class RNN(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(RNN, self).__init__()\n",
            "        self.layers = torch.nn.Sequential(torch.nn.Linear(108, 64),\n",
            "                                          torch.nn.ReLU(),\n",
            "                                          torch.nn.Linear(64, 73))\n",
            "        \n",
            "    def forward(self, inputs, hidden):\n",
            "        # combined = torch.tensor([inputs, hidden]).to(inputs.device)\n",
            "        # print(inputs.shape)\n",
            "        # print(hidden.shape)\n",
            "        combined = torch.cat([inputs, hidden]).to(inputs.device)\n",
            "        out = self.layers(combined)\n",
            "        return out"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Sequential(\n",
                  "  (0): Linear(in_features=108, out_features=64, bias=True)\n",
                  "  (1): ReLU()\n",
                  "  (2): Linear(in_features=64, out_features=73, bias=True)\n",
                  ")\n"
               ]
            }
         ],
         "source": [
            "model = RNN().to(device)\n",
            "print(model.layers)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "def train(model, dataloader, num_epochs, learning_rate, device):\n",
            "    criterion = torch.nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
            "    # hidden = torch.tensor([0]).to(device)\n",
            "    # hidden= torch.zeros(1, 81, 54).to(device)\n",
            "    for epoch in range(num_epochs):\n",
            "        count = 0\n",
            "        loss = 0\n",
            "\n",
            "        \n",
            "        # optimizer.zero_grad()\n",
            "        for inputs, targets in dataloader:\n",
            "            # inputs = inputs.permute(1,0,2)\n",
            "            # need another loop inside.\n",
            "            correct = 0\n",
            "            pred = 0\n",
            "            \n",
            "            # reset hidden here\n",
            "            loss = 0\n",
            "            optimizer.zero_grad()\n",
            "            # \n",
            "            for i in range(len(inputs)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(inputs[i])):\n",
            "                    outputs = model(inputs[i][j].to(device), hidden)\n",
            "                    out, hidden = outputs[0:19], outputs[19::]\n",
            "                    # print(out.shape)\n",
            "                    # print(hidden.shape)\n",
            "                    # print(targets[i][j].shape)\n",
            "\n",
            "                    # print((torch.argmax(out) == targets[i][j]).item())\n",
            "                    correct += (torch.argmax(out) == targets[i][j]).item()\n",
            "                    pred += 1\n",
            "                    loss += criterion(out.to(device), targets[i][j].to(device)) / len(inputs[i]) / len(inputs)\n",
            "                # print(loss)\n",
            "            batch_accuracy = correct/pred\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "            count +=1\n",
            "            # print(f\"Batch number: {count}\")\n",
            "            print(f\"Batch {count} accuracy: {batch_accuracy}\")\n",
            "        \n",
            "        # loss /= len(inputs)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        #     outputs = model(inputs.to(device), hidden)\n",
            "        #     out, hidden = outputs[0], outputs[1]\n",
            "        #     loss += criterion(out.to(device), targets.to(device))\n",
            "        # loss /= len(dataloader)\n",
            "        # loss.backward()\n",
            "        # optimizer.step()\n",
            "\n",
            "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Last Batch Accuracy: {batch_accuracy*100:.2f}%\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.45003858024691357\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.4512924382716049\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.4497492283950617\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.44675925925925924\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.44743441358024694\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.45206404320987653\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.4489776234567901\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.4513888888888889\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.45380015432098764\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.45003858024691357\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.4575617283950617\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.44319058641975306\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.4540895061728395\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.45100308641975306\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.4525462962962963\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.4498456790123457\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.46084104938271603\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.4591049382716049\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.4575617283950617\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.4575617283950617\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.45987654320987653\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.4617091049382716\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.4599729938271605\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.4620949074074074\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.4637345679012346\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.45717592592592593\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.45949074074074076\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.4634452160493827\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.47444058641975306\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.4670138888888889\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.4624807098765432\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.45380015432098764\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.46315586419753085\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.45881558641975306\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.46219135802469136\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.46296296296296297\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.46315586419753085\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.47116126543209874\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.4607445987654321\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.46479552469135804\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.4636381172839506\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.46576003086419754\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.4662422839506173\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.46045524691358025\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.4699074074074074\n",
                  "Epoch 2/10, Loss: 1.6464, Last Batch Accuracy: 46.99%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.4659529320987654\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.47173996913580246\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.4600694444444444\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.46141975308641975\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.47550154320987653\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.4777199074074074\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.47434413580246915\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.4818672839506173\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.4681712962962963\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.47665895061728397\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.4757908950617284\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.47704475308641975\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.4740547839506173\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.47453703703703703\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.4750192901234568\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.47415123456790126\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.4714506172839506\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.4695216049382716\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.4761766975308642\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.4644097222222222\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.4754050925925926\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.4712577160493827\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.4728973765432099\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.47550154320987653\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.48042052469135804\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.48408564814814814\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.4866898148148148\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.4662422839506173\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.4696180555555556\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.4792631172839506\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.47858796296296297\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.4782986111111111\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.48234953703703703\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.47646604938271603\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.48466435185185186\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.48273533950617287\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.484375\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.4809027777777778\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.47521219135802467\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.4832175925925926\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.4769483024691358\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.48215663580246915\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.4896797839506173\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.48842592592592593\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.48996913580246915\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.4790702160493827\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.48369984567901236\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.48466435185185186\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.4913194444444444\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.4815779320987654\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.4839891975308642\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.4945023148148148\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.49247685185185186\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5036651234567902\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.49170524691358025\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.4808063271604938\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.4918016975308642\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.49353780864197533\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.4834104938271605\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.49074074074074076\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.4964313271604938\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.49517746913580246\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5064621913580247\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.48755787037037035\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.49440586419753085\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.4904513888888889\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.48996913580246915\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.49266975308641975\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.49594907407407407\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.49286265432098764\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.49604552469135804\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.49421296296296297\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.4992283950617284\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.4948881172839506\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5111882716049383\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5027970679012346\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5033757716049383\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5050154320987654\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.46219135802469136\n",
                  "Epoch 3/10, Loss: 1.6590, Last Batch Accuracy: 46.22%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.4957561728395062\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.49787808641975306\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.49691358024691357\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.49778163580246915\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5037615740740741\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5028935185185185\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.49266975308641975\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5142746913580247\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5002893518518519\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5017361111111112\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.49855324074074076\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5052083333333334\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.4984567901234568\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5005787037037037\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.4988425925925926\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.509741512345679\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5031828703703703\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5030864197530864\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5010609567901234\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5082947530864198\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5049189814814815\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5126350308641975\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5106095679012346\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5053047839506173\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.49855324074074076\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5091628086419753\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5054976851851852\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5102237654320988\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5052083333333334\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5000964506172839\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5052083333333334\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5135030864197531\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5023148148148148\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5158179012345679\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5149498456790124\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5113811728395061\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5121527777777778\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5100308641975309\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.517554012345679\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5138888888888888\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5101273148148148\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5145640432098766\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5128279320987654\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5108024691358025\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5220871913580247\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.5167824074074074\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.4981674382716049\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5108989197530864\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5177469135802469\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5182291666666666\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5129243827160493\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5208333333333334\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5213155864197531\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5233410493827161\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5132137345679012\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5154320987654321\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5173611111111112\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5191936728395061\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5200617283950617\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5170717592592593\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5220871913580247\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5251736111111112\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5209297839506173\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5258487654320988\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5203510802469136\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5098379629629629\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5204475308641975\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5164930555555556\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5306712962962963\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5256558641975309\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5126350308641975\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5315393518518519\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5211226851851852\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.521508487654321\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5196759259259259\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5269097222222222\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5183256172839507\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5248842592592593\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5300925925925926\n",
                  "Epoch 4/10, Loss: 1.4586, Last Batch Accuracy: 53.01%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.5190007716049383\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5243055555555556\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.5173611111111112\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5302854938271605\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5210262345679012\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5256558641975309\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5241126543209876\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5304783950617284\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5291280864197531\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5313464506172839\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5244984567901234\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5297067901234568\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5265239197530864\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5184220679012346\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.5244020061728395\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5271026234567902\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5310570987654321\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5271026234567902\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5274884259259259\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5265239197530864\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5317322530864198\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5386766975308642\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.537133487654321\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5335648148148148\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.5254629629629629\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5319251543209876\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5152391975308642\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5261381172839507\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5349151234567902\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.53125\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5401234567901234\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5341435185185185\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5276813271604939\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5342399691358025\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5283564814814815\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5354938271604939\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5420524691358025\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5307677469135802\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5244984567901234\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5372299382716049\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5297067901234568\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5380979938271605\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5258487654320988\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5344328703703703\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5380015432098766\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.5362654320987654\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5359760802469136\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5286458333333334\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5359760802469136\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5330825617283951\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5394483024691358\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5348186728395061\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5319251543209876\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5386766975308642\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5332754629629629\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5471643518518519\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5438850308641975\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5436921296296297\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5434992283950617\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5406057098765432\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5403163580246914\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5434992283950617\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5391589506172839\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5421489197530864\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5461033950617284\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5434992283950617\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5414737654320988\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5393518518518519\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5407021604938271\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5421489197530864\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5403163580246914\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5395447530864198\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5345293209876543\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5368441358024691\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5378086419753086\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5526620370370371\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5378086419753086\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5401234567901234\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5239197530864198\n",
                  "Epoch 5/10, Loss: 1.4674, Last Batch Accuracy: 52.39%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.548804012345679\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5542052469135802\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.5389660493827161\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5484182098765432\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5455246913580247\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5422453703703703\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5407986111111112\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5419560185185185\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5486111111111112\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5450424382716049\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5491898148148148\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5455246913580247\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5399305555555556\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5556520061728395\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.5515046296296297\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5496720679012346\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5524691358024691\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5474537037037037\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5380979938271605\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5406057098765432\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5484182098765432\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5456211419753086\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5444637345679012\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5485146604938271\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.5522762345679012\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5535300925925926\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.552758487654321\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5465856481481481\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5424382716049383\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5518904320987654\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5463927469135802\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5476466049382716\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5517939814814815\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5578703703703703\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5550733024691358\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5370370370370371\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5407986111111112\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5426311728395061\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5505401234567902\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5509259259259259\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5494791666666666\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5470679012345679\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5556520061728395\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5642361111111112\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5550733024691358\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.5548804012345679\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5528549382716049\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5463927469135802\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5547839506172839\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5520833333333334\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5489004629629629\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5513117283950617\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5616319444444444\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5556520061728395\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5543016975308642\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5589313271604939\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.564429012345679\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5555555555555556\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5447530864197531\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5549768518518519\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5498649691358025\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5540123456790124\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5524691358024691\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5548804012345679\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5551697530864198\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.544945987654321\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5570023148148148\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5531442901234568\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5522762345679012\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5548804012345679\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5543981481481481\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5633680555555556\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5570023148148148\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5602816358024691\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5515046296296297\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5558449074074074\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5647183641975309\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5539158950617284\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5748456790123457\n",
                  "Epoch 6/10, Loss: 1.3559, Last Batch Accuracy: 57.48%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.5623070987654321\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5595100308641975\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.5551697530864198\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5514081790123457\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5576774691358025\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5526620370370371\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5634645061728395\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5572916666666666\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5517939814814815\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5519868827160493\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5499614197530864\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5577739197530864\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5577739197530864\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5524691358024691\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.5658757716049383\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5609567901234568\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5569058641975309\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5659722222222222\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5576774691358025\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5569058641975309\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5667438271604939\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5599922839506173\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5660686728395061\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5760995370370371\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.5573881172839507\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5651041666666666\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5610532407407407\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5646219135802469\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5662615740740741\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5538194444444444\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5614390432098766\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5545910493827161\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5460069444444444\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5571952160493827\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5577739197530864\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5571952160493827\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5598958333333334\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5606674382716049\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5667438271604939\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5547839506172839\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5621141975308642\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5672260802469136\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5679012345679012\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5704089506172839\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5581597222222222\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.568383487654321\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5745563271604939\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5645254629629629\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5674189814814815\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5647183641975309\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5609567901234568\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5501543209876543\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5510223765432098\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5672260802469136\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5737847222222222\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5685763888888888\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5616319444444444\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5669367283950617\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5645254629629629\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5639467592592593\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5603780864197531\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5686728395061729\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5656828703703703\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5633680555555556\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5735918209876543\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5632716049382716\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5652006172839507\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5725308641975309\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5631751543209876\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5616319444444444\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5752314814814815\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5629822530864198\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5733024691358025\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5668402777777778\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5700231481481481\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.558641975308642\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5751350308641975\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5760030864197531\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.566358024691358\n",
                  "Epoch 7/10, Loss: 1.3203, Last Batch Accuracy: 56.64%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.5615354938271605\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5669367283950617\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.5631751543209876\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5786072530864198\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5595100308641975\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5660686728395061\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5677083333333334\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5730131172839507\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5639467592592593\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5696373456790124\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5706018518518519\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5671296296296297\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5654899691358025\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5686728395061729\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.566454475308642\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5747492283950617\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5631751543209876\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5633680555555556\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5713734567901234\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5711805555555556\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5792824074074074\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5641396604938271\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5654899691358025\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5625\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.5724344135802469\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5758101851851852\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5711805555555556\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5603780864197531\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5769675925925926\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5804398148148148\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5553626543209876\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5673225308641975\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5777391975308642\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5718557098765432\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5701195987654321\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5757137345679012\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5746527777777778\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5693479938271605\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5706018518518519\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5701195987654321\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5767746913580247\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5703125\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5726273148148148\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5760030864197531\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5788001543209876\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.5736882716049383\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5708912037037037\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5675154320987654\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5755208333333334\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5735918209876543\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5825617283950617\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5788001543209876\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5749421296296297\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.584008487654321\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5777391975308642\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5691550925925926\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5730131172839507\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5826581790123457\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5706983024691358\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5751350308641975\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5754243827160493\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5797646604938271\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5666473765432098\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5828510802469136\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5659722222222222\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5789930555555556\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5714699074074074\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5748456790123457\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5881558641975309\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5739776234567902\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5746527777777778\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5780285493827161\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5717592592592593\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5784143518518519\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5801504629629629\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.581983024691358\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5765817901234568\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5701195987654321\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5879629629629629\n",
                  "Epoch 8/10, Loss: 1.2565, Last Batch Accuracy: 58.80%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.5675154320987654\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5760995370370371\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.578125\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5708912037037037\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5787037037037037\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.5784143518518519\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5746527777777778\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5842978395061729\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.5643325617283951\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5757137345679012\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5735918209876543\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5842013888888888\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5732060185185185\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5857445987654321\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.5786072530864198\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5787037037037037\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5806327160493827\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5814043209876543\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5767746913580247\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5792824074074074\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5793788580246914\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5877700617283951\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5758101851851852\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5764853395061729\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.581983024691358\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5753279320987654\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5823688271604939\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5831404320987654\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5759066358024691\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5779320987654321\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5732060185185185\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.5777391975308642\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5851658950617284\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5852623456790124\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5730131172839507\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5811149691358025\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5841049382716049\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5790895061728395\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5773533950617284\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5807291666666666\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5814043209876543\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5771604938271605\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5776427469135802\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5835262345679012\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5914351851851852\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.5848765432098766\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5855516975308642\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5856481481481481\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5824652777777778\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5849729938271605\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5762924382716049\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5855516975308642\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5787037037037037\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.5883487654320988\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5821759259259259\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5818865740740741\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5746527777777778\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5924961419753086\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5859375\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.574170524691358\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5797646604938271\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5848765432098766\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5883487654320988\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5861304012345679\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.587866512345679\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5936535493827161\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5794753086419753\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5836226851851852\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5931712962962963\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.5777391975308642\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5790895061728395\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5892168209876543\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5780285493827161\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5817901234567902\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.581983024691358\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5813078703703703\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5718557098765432\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5847800925925926\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5763888888888888\n",
                  "Epoch 9/10, Loss: 1.2917, Last Batch Accuracy: 57.64%\n",
                  "Batch number: 1\n",
                  "Batch 1 accuracy: 0.5857445987654321\n",
                  "Batch number: 2\n",
                  "Batch 2 accuracy: 0.5892168209876543\n",
                  "Batch number: 3\n",
                  "Batch 3 accuracy: 0.5815972222222222\n",
                  "Batch number: 4\n",
                  "Batch 4 accuracy: 0.5767746913580247\n",
                  "Batch number: 5\n",
                  "Batch 5 accuracy: 0.5808256172839507\n",
                  "Batch number: 6\n",
                  "Batch 6 accuracy: 0.584008487654321\n",
                  "Batch number: 7\n",
                  "Batch 7 accuracy: 0.5970293209876543\n",
                  "Batch number: 8\n",
                  "Batch 8 accuracy: 0.5823688271604939\n",
                  "Batch number: 9\n",
                  "Batch 9 accuracy: 0.582079475308642\n",
                  "Batch number: 10\n",
                  "Batch 10 accuracy: 0.5899884259259259\n",
                  "Batch number: 11\n",
                  "Batch 11 accuracy: 0.5788001543209876\n",
                  "Batch number: 12\n",
                  "Batch 12 accuracy: 0.5814043209876543\n",
                  "Batch number: 13\n",
                  "Batch 13 accuracy: 0.5902777777777778\n",
                  "Batch number: 14\n",
                  "Batch 14 accuracy: 0.5821759259259259\n",
                  "Batch number: 15\n",
                  "Batch 15 accuracy: 0.5873842592592593\n",
                  "Batch number: 16\n",
                  "Batch 16 accuracy: 0.5785108024691358\n",
                  "Batch number: 17\n",
                  "Batch 17 accuracy: 0.5932677469135802\n",
                  "Batch number: 18\n",
                  "Batch 18 accuracy: 0.5873842592592593\n",
                  "Batch number: 19\n",
                  "Batch 19 accuracy: 0.5855516975308642\n",
                  "Batch number: 20\n",
                  "Batch 20 accuracy: 0.5874807098765432\n",
                  "Batch number: 21\n",
                  "Batch 21 accuracy: 0.5907600308641975\n",
                  "Batch number: 22\n",
                  "Batch 22 accuracy: 0.5771604938271605\n",
                  "Batch number: 23\n",
                  "Batch 23 accuracy: 0.5880594135802469\n",
                  "Batch number: 24\n",
                  "Batch 24 accuracy: 0.5924961419753086\n",
                  "Batch number: 25\n",
                  "Batch 25 accuracy: 0.5786072530864198\n",
                  "Batch number: 26\n",
                  "Batch 26 accuracy: 0.5914351851851852\n",
                  "Batch number: 27\n",
                  "Batch 27 accuracy: 0.5864197530864198\n",
                  "Batch number: 28\n",
                  "Batch 28 accuracy: 0.5899884259259259\n",
                  "Batch number: 29\n",
                  "Batch 29 accuracy: 0.5860339506172839\n",
                  "Batch number: 30\n",
                  "Batch 30 accuracy: 0.5903742283950617\n",
                  "Batch number: 31\n",
                  "Batch 31 accuracy: 0.5846836419753086\n",
                  "Batch number: 32\n",
                  "Batch 32 accuracy: 0.580054012345679\n",
                  "Batch number: 33\n",
                  "Batch 33 accuracy: 0.5870949074074074\n",
                  "Batch number: 34\n",
                  "Batch 34 accuracy: 0.5857445987654321\n",
                  "Batch number: 35\n",
                  "Batch 35 accuracy: 0.5889274691358025\n",
                  "Batch number: 36\n",
                  "Batch 36 accuracy: 0.5849729938271605\n",
                  "Batch number: 37\n",
                  "Batch 37 accuracy: 0.5867091049382716\n",
                  "Batch number: 38\n",
                  "Batch 38 accuracy: 0.5889274691358025\n",
                  "Batch number: 39\n",
                  "Batch 39 accuracy: 0.5939429012345679\n",
                  "Batch number: 40\n",
                  "Batch 40 accuracy: 0.5874807098765432\n",
                  "Batch number: 41\n",
                  "Batch 41 accuracy: 0.5951967592592593\n",
                  "Batch number: 42\n",
                  "Batch 42 accuracy: 0.5903742283950617\n",
                  "Batch number: 43\n",
                  "Batch 43 accuracy: 0.5912422839506173\n",
                  "Batch number: 44\n",
                  "Batch 44 accuracy: 0.5865162037037037\n",
                  "Batch number: 45\n",
                  "Batch 45 accuracy: 0.5879629629629629\n",
                  "Batch number: 46\n",
                  "Batch 46 accuracy: 0.584008487654321\n",
                  "Batch number: 47\n",
                  "Batch 47 accuracy: 0.5934606481481481\n",
                  "Batch number: 48\n",
                  "Batch 48 accuracy: 0.5979938271604939\n",
                  "Batch number: 49\n",
                  "Batch 49 accuracy: 0.5864197530864198\n",
                  "Batch number: 50\n",
                  "Batch 50 accuracy: 0.5828510802469136\n",
                  "Batch number: 51\n",
                  "Batch 51 accuracy: 0.5929783950617284\n",
                  "Batch number: 52\n",
                  "Batch 52 accuracy: 0.5959683641975309\n",
                  "Batch number: 53\n",
                  "Batch 53 accuracy: 0.5939429012345679\n",
                  "Batch number: 54\n",
                  "Batch 54 accuracy: 0.587866512345679\n",
                  "Batch number: 55\n",
                  "Batch 55 accuracy: 0.5928819444444444\n",
                  "Batch number: 56\n",
                  "Batch 56 accuracy: 0.5848765432098766\n",
                  "Batch number: 57\n",
                  "Batch 57 accuracy: 0.5838155864197531\n",
                  "Batch number: 58\n",
                  "Batch 58 accuracy: 0.5914351851851852\n",
                  "Batch number: 59\n",
                  "Batch 59 accuracy: 0.5885416666666666\n",
                  "Batch number: 60\n",
                  "Batch 60 accuracy: 0.5888310185185185\n",
                  "Batch number: 61\n",
                  "Batch 61 accuracy: 0.5872878086419753\n",
                  "Batch number: 62\n",
                  "Batch 62 accuracy: 0.5913387345679012\n",
                  "Batch number: 63\n",
                  "Batch 63 accuracy: 0.5906635802469136\n",
                  "Batch number: 64\n",
                  "Batch 64 accuracy: 0.5854552469135802\n",
                  "Batch number: 65\n",
                  "Batch 65 accuracy: 0.5933641975308642\n",
                  "Batch number: 66\n",
                  "Batch 66 accuracy: 0.5944251543209876\n",
                  "Batch number: 67\n",
                  "Batch 67 accuracy: 0.5948109567901234\n",
                  "Batch number: 68\n",
                  "Batch 68 accuracy: 0.5922067901234568\n",
                  "Batch number: 69\n",
                  "Batch 69 accuracy: 0.5908564814814815\n",
                  "Batch number: 70\n",
                  "Batch 70 accuracy: 0.597608024691358\n",
                  "Batch number: 71\n",
                  "Batch 71 accuracy: 0.5868055555555556\n",
                  "Batch number: 72\n",
                  "Batch 72 accuracy: 0.5938464506172839\n",
                  "Batch number: 73\n",
                  "Batch 73 accuracy: 0.5910493827160493\n",
                  "Batch number: 74\n",
                  "Batch 74 accuracy: 0.5972222222222222\n",
                  "Batch number: 75\n",
                  "Batch 75 accuracy: 0.5882523148148148\n",
                  "Batch number: 76\n",
                  "Batch 76 accuracy: 0.5915316358024691\n",
                  "Batch number: 77\n",
                  "Batch 77 accuracy: 0.5946180555555556\n",
                  "Batch number: 78\n",
                  "Batch 78 accuracy: 0.5911458333333334\n",
                  "Batch number: 79\n",
                  "Batch 79 accuracy: 0.5972222222222222\n",
                  "Epoch 10/10, Loss: 1.2325, Last Batch Accuracy: 59.72%\n"
               ]
            }
         ],
         "source": [
            "# Train the model\n",
            "model = RNN().to(device)\n",
            "train(model, dataloader, num_epochs = 10, learning_rate = 0.001, device = device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the model use new names each time tyvm\n",
            "torch.save(model.state_dict(), 'weights/rnn_2layer_64_10epoch.pth')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Load the model\n",
            "model = RNN().to(device)\n",
            "model.load_state_dict(torch.load('weights/rnn_2layer_64_1.pth', map_location=torch.device('cpu')))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\joen\\AppData\\Local\\Temp\\ipykernel_5176\\414264106.py:1: DtypeWarning: Columns (69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n"
               ]
            }
         ],
         "source": [
            "test_dataset = pd.read_csv(\"dataset/training99_sort.csv\")\n",
            "test_dataset.fillna(\"0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5,#\", inplace=True)\n",
            "test_rubiksdataset = RubiksDataset(test_dataset)\n",
            "test_dataloader = DataLoader(test_rubiksdataset, batch_size = 128)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 70,
         "metadata": {},
         "outputs": [],
         "source": [
            "def test(model, test_loader, device):\n",
            "    model.eval()\n",
            "    # test_loss = 0\n",
            "    correct = 0\n",
            "    pred = 0\n",
            "    count = 0\n",
            "    # criterion = torch.nn.CrossEntropyLoss()\n",
            "    with torch.no_grad():\n",
            "        for data, target in test_loader:\n",
            "            for i in range(len(data)):\n",
            "                hidden= torch.zeros(54).to(device)\n",
            "                for j in range(len(data[i])):\n",
            "                    output = model(data[i][j].to(device), hidden)\n",
            "                    out, hidden = output[0:19], output[19::]\n",
            "                    # test_loss += criterion(out.to(device), target[i][j].to(device)) / len(data[i]) / len(data)\n",
            "                    # pred = out.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
            "                    # correct += pred.eq(target.view_as(pred)).sum().item()\n",
            "                    # if args.dry_run:\n",
            "                    #     break\n",
            "                    correct += (torch.argmax(out) == target[i][j]).item()\n",
            "                    pred += 1\n",
            "            batch_accuracy = correct/pred\n",
            "\n",
            "    # test_loss /= len(test_loader.dataset)\n",
            "\n",
            "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
            "    #     test_loss, correct, len(test_loader.dataset),\n",
            "    #     100. * correct / len(test_loader.dataset)))\n",
            "    count +=1\n",
            "    print(f\"Batch {count} accuracy: {batch_accuracy}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 71,
         "metadata": {},
         "outputs": [
            {
               "ename": "IndexError",
               "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                  "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
                  "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, test_loader, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 out, hidden \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m19\u001b[39m], output[\u001b[38;5;241m19\u001b[39m::]\n\u001b[0;32m     15\u001b[0m                 \u001b[38;5;66;03m# test_loss += criterion(out.to(device), target[i][j].to(device)) / len(data[i]) / len(data)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m                 pred \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n\u001b[0;32m     17\u001b[0m                 correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target\u001b[38;5;241m.\u001b[39mview_as(pred))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m                 \u001b[38;5;66;03m# if args.dry_run:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m                 \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[0;32m     20\u001b[0m                 \u001b[38;5;66;03m# correct += (torch.argmax(out) == target[i][j]).item()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#     test_loss, correct, len(test_loader.dataset),\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#     100. * correct / len(test_loader.dataset)))\u001b[39;00m\n",
                  "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
               ]
            }
         ],
         "source": [
            "test(model, test_dataloader, device=device)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# shawns stuff"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# split data into features\n",
            "targets_numpy = train.label.values\n",
            "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
            "\n",
            "# train test split. Size of train data is 80% and size of test data is 20%. \n",
            "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
            "                                                                             targets_numpy,\n",
            "                                                                             test_size = 0.2,\n",
            "                                                                             random_state = 42) \n",
            "\n",
            "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
            "featuresTrain = torch.from_numpy(features_train)\n",
            "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
            "\n",
            "# create feature and targets tensor for test set.\n",
            "featuresTest = torch.from_numpy(features_test)\n",
            "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
            "\n",
            "# batch_size, epoch and iteration\n",
            "batch_size = 100\n",
            "n_iters = 10000\n",
            "num_epochs = n_iters / (len(features_train) / batch_size)\n",
            "num_epochs = int(num_epochs)\n",
            "\n",
            "# Pytorch train and test sets\n",
            "train = TensorDataset(featuresTrain,targetsTrain)\n",
            "test = TensorDataset(featuresTest,targetsTest)\n",
            "\n",
            "# data loader\n",
            "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
            "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
            "\n",
            "# visualize one of the images in data set\n",
            "plt.imshow(features_numpy[10].reshape(28,28))\n",
            "plt.axis(\"off\")\n",
            "plt.title(str(targets_numpy[10]))\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'features_train' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                  "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     30\u001b[0m n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8000\u001b[39m\n\u001b[1;32m---> 31\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m n_iters \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mfeatures_train\u001b[49m) \u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[0;32m     32\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(num_epochs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Pytorch train and test sets\u001b[39;00m\n",
                  "\u001b[1;31mNameError\u001b[0m: name 'features_train' is not defined"
               ]
            }
         ],
         "source": [
            "# Create RNN Model\n",
            "class RNNModel(nn.Module):\n",
            "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
            "        super(RNNModel, self).__init__()\n",
            "        \n",
            "        # Number of hidden dimensions\n",
            "        self.hidden_dim = hidden_dim\n",
            "        \n",
            "        # Number of hidden layers\n",
            "        self.layer_dim = layer_dim\n",
            "        \n",
            "        # RNN\n",
            "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
            "        \n",
            "        # Readout layer\n",
            "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
            "    \n",
            "    def forward(self, x):\n",
            "        \n",
            "        # Initialize hidden state with zeros\n",
            "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
            "            \n",
            "        # One time step\n",
            "        out, hn = self.rnn(x, h0)\n",
            "        out = self.fc(out[:, -1, :]) \n",
            "        return out\n",
            "\n",
            "# batch_size, epoch and iteration\n",
            "batch_size = 100\n",
            "n_iters = 8000\n",
            "num_epochs = n_iters / (len(features_train) / batch_size)\n",
            "num_epochs = int(num_epochs)\n",
            "\n",
            "# Pytorch train and test sets\n",
            "train = TensorDataset(featuresTrain,targetsTrain)\n",
            "test = TensorDataset(featuresTest,targetsTest)\n",
            "\n",
            "# data loader\n",
            "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
            "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
            "    \n",
            "# Create RNN\n",
            "input_dim = 28    # input dimension\n",
            "hidden_dim = 100  # hidden layer dimension\n",
            "layer_dim = 1     # number of hidden layers\n",
            "output_dim = 10   # output dimension\n",
            "\n",
            "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
            "\n",
            "# Cross Entropy Loss \n",
            "error = nn.CrossEntropyLoss()\n",
            "\n",
            "# SGD Optimizer\n",
            "learning_rate = 0.05\n",
            "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Training model\n",
            "seq_dim = 28  \n",
            "loss_list = []\n",
            "iteration_list = []\n",
            "accuracy_list = []\n",
            "count = 0\n",
            "for epoch in range(num_epochs):\n",
            "    for i, (images, labels) in enumerate(train_loader):\n",
            "\n",
            "        train  = Variable(images.view(-1, seq_dim, input_dim))\n",
            "        labels = Variable(labels )\n",
            "            \n",
            "        # Clear gradients\n",
            "        optimizer.zero_grad()\n",
            "        \n",
            "        # Forward propagation\n",
            "        outputs = model(train)\n",
            "        \n",
            "        # Calculate softmax and ross entropy loss\n",
            "        loss = error(outputs, labels)\n",
            "        \n",
            "        # Calculating gradients\n",
            "        loss.backward()\n",
            "        \n",
            "        # Update parameters\n",
            "        optimizer.step()\n",
            "        \n",
            "        count += 1\n",
            "        \n",
            "        if count % 250 == 0:\n",
            "            # Calculate Accuracy         \n",
            "            correct = 0\n",
            "            total = 0\n",
            "            # Iterate through test dataset\n",
            "            for images, labels in test_loader:\n",
            "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
            "                \n",
            "                # Forward propagation\n",
            "                outputs = model(images)\n",
            "                \n",
            "                # Get predictions from the maximum value\n",
            "                predicted = torch.max(outputs.data, 1)[1]\n",
            "                \n",
            "                # Total number of labels\n",
            "                total += labels.size(0)\n",
            "                \n",
            "                correct += (predicted == labels).sum()\n",
            "            \n",
            "            accuracy = 100 * correct / float(total)\n",
            "            \n",
            "            # store loss and iteration\n",
            "            loss_list.append(loss.data)\n",
            "            iteration_list.append(count)\n",
            "            accuracy_list.append(accuracy)\n",
            "            if count % 500 == 0:\n",
            "                # Print Loss\n",
            "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# visualization loss \n",
            "plt.plot(iteration_list,loss_list)\n",
            "plt.xlabel(\"Number of iteration\")\n",
            "plt.ylabel(\"Loss\")\n",
            "plt.title(\"RNN: Loss vs Number of iteration\")\n",
            "plt.show()\n",
            "\n",
            "# visualization accuracy \n",
            "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
            "plt.xlabel(\"Number of iteration\")\n",
            "plt.ylabel(\"Accuracy\")\n",
            "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
            "plt.savefig('graph.png')\n",
            "plt.show()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.5"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
